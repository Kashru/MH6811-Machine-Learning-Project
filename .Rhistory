# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = y.keras.ohc,
shuffle = T,
epochs = 300
)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = as.factor(pd.train.Y),
shuffle = T,
epochs = 300
)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
View(ffnn.train.X.scaled)
# Standardization of the features:
library(CatEncoders)
t <- function(x) {
# check if x is numeric
if(is.numeric(x)) {
return (x)
}
l <- LabelEncoder.fit(x)
y <- transform(l, x)
return (y)
}
ffnn.train.X <- sapply(pd.train.X, t)
ffnn.test.X <- sapply(pd.test.X, t)
ffnn.train.X.mean <- apply(ffnn.train.X, 2, mean)
ffnn.train.X.sd <- apply(ffnn.train.X, 2, sd)
ffnn.train.X.scaled<-scale(ffnn.train.X,center=ffnn.train.X.mean,scale=ffnn.train.X.sd)
ffnn.test.X.scaled<-scale(ffnn.test.X,center=ffnn.train.X.mean,scale=ffnn.train.X.sd)
ffnn.train.scaled<-data.frame(ffnn.train.X.scaled,Loan_Status=pd.train.Y)
ffnn.test.scaled<-data.frame(ffnn.test.X.scaled,Loan_Status=pd.test.Y)
ffnn.train.X.scaled<-as.matrix(ffnn.train.X.scaled)
ffnn.test.X.scaled<-as.matrix(ffnn.test.X.scaled)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = as.matrix(ffnn.train.X.scaled),
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
# Standardization of the features:
library(CatEncoders)
t <- function(x) {
# check if x is numeric
if(is.numeric(x)) {
return (x)
}
l <- LabelEncoder.fit(x)
y <- transform(l, x)
return (y)
}
ffnn.train.X <- sapply(pd.train.X, t)
ffnn.test.X <- sapply(pd.test.X, t)
ffnn.train.X.mean <- apply(ffnn.train.X, 2, mean)
ffnn.train.X.sd <- apply(ffnn.train.X, 2, sd)
ffnn.train.X.scaled<-scale(ffnn.train.X,center=ffnn.train.X.mean,scale=ffnn.train.X.sd)
ffnn.test.X.scaled<-scale(ffnn.test.X,center=ffnn.train.X.mean,scale=ffnn.train.X.sd)
ffnn.train.scaled<-data.frame(ffnn.train.X.scaled,Loan_Status=pd.train.Y)
ffnn.test.scaled<-data.frame(ffnn.test.X.scaled,Loan_Status=pd.test.Y)
#ffnn.train.X.scaled<-as.matrix(ffnn.train.X.scaled)
#ffnn.test.X.scaled<-as.matrix(ffnn.test.X.scaled)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
# Standardization of the features:
library(CatEncoders)
t <- function(x) {
# check if x is numeric
if(is.numeric(x)) {
return (x)
}
l <- LabelEncoder.fit(x)
y <- transform(l, x)
return (y)
}
ffnn.train.X <- sapply(pd.train.X, t)
ffnn.test.X <- sapply(pd.test.X, t)
ffnn.train.X.mean <- apply(ffnn.train.X, 2, mean)
ffnn.train.X.sd <- apply(ffnn.train.X, 2, sd)
ffnn.train.X.scaled<-scale(ffnn.train.X,center=ffnn.train.X.mean,scale=ffnn.train.X.sd)
ffnn.test.X.scaled<-scale(ffnn.test.X,center=ffnn.train.X.mean,scale=ffnn.train.X.sd)
ffnn.train.scaled<-data.frame(ffnn.train.X.scaled,Loan_Status=pd.train.Y)
ffnn.test.scaled<-data.frame(ffnn.test.X.scaled,Loan_Status=pd.test.Y)
ffnn.train.X.scaled<-as.matrix(ffnn.train.X.scaled)
ffnn.test.X.scaled<-as.matrix(ffnn.test.X.scaled)
str(ffnn.train.X.scaled)
wtf <- as.matrix(ffnn.train.X.scaled)
View(wtf)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = wtf,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
View(y.keras.ohc)
# Feedforward Neural Networks with Keras and TensorFlow
library(keras)
library(tensorflow)
y.keras <- as.factor(pd.train.Y)
levels(y.keras) = 0:1
y.keras.ohc = to_categorical(y.keras , num_classes = 2)
# Feedforward Neural Networks with Keras and TensorFlow
library(keras)
library(tensorflow)
y.keras <- as.factor(pd.train.Y)
y.keras.ohc = to_categorical(y.keras , num_classes = 2)
# Feedforward Neural Networks with Keras and TensorFlow
library(keras)
library(tensorflow)
y.keras <- as.factor(pd.train.Y)
levels(y.keras) = 0:1
y.keras.ohc = to_categorical(y.keras , num_classes = 2)
View(y.keras.ohc)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = wtf,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
ncol(ffnn.train.X.scaled)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = pd.train.X,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
# Feedforward Neural Networks with Keras and TensorFlow
library(keras)
library(tensorflow)
y.keras <- as.factor(pd.train.Y)
levels(y.keras) = 1:2
y.keras.ohc = to_categorical(y.keras , num_classes = 2)
# Feedforward Neural Networks with Keras and TensorFlow
library(keras)
library(tensorflow)
y.keras <- as.factor(pd.train.Y)
levels(y.keras) = c("N","Y")
y.keras.ohc = to_categorical(y.keras , num_classes = 2)
# Feedforward Neural Networks with Keras and TensorFlow
library(keras)
library(tensorflow)
y.keras <- as.factor(pd.train.Y)
levels(y.keras) = 0:1
y.keras.ohc = to_categorical(y.keras , num_classes = 2)
library(keras)
library(tensorflow)
data(iris)
library(keras)
library(tensorflow)
data(iris)
# summary(iris)
set.seed(1)
train <- sample(nrow(iris), 0.7 * nrow(iris))
X.train <- subset(iris[train, ],select=-Species)
y.train <- iris$Species[train]
X.test <- subset(iris[-train, ],select=-Species)
y.test <- iris$Species[-train]
X.train.mean <- apply(X.train, 2, mean)
X.train.sd <- apply(X.train, 2, sd)
X.train.scaled<-scale(X.train,center=X.train.mean,scale=X.train.sd)
X.test.scaled<-scale(X.test,center=X.train.mean,scale=X.train.sd)
# iris.train<-data.frame(X.train,Species=y.train)
# iris.test<-data.frame(X.test,Species=y.test)
iris.train.scaled<-data.frame(X.train.scaled,Species=y.train)
iris.test.scaled<-data.frame(X.test.scaled,Species=y.test)
# X.train<-as.matrix(X.train)
X.train.scaled<-as.matrix(X.train.scaled)
# X.test<-as.matrix(X.test)
X.test.scaled<-as.matrix(X.test.scaled)
y <- y.train
levels(y) = 0:2
y.train.ohc = to_categorical(y , num_classes = 3)
View(X.train.scaled)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 2, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = y.keras.ohc,
shuffle = T,
epochs = 30
)
set.seed(114514)
# create sequential model
ffnn.keras.model = keras_model_sequential()
# add layers, first layer needs input dimension
ffnn.keras.model %>%
layer_dense(input_shape = ncol(ffnn.train.X.scaled), units = 10, activation = "relu") %>%
layer_dense(units = 10, activation = "relu") %>%
layer_dense(units = 2, activation = "softmax")
# add a loss function and optimizer
ffnn.keras.model %>%
compile(
loss = "categorical_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
# fit model with our training data set, training will be done for 200 times data set
loan.ffnn.keras = ffnn.keras.model %>%
fit(
x = ffnn.train.X.scaled,
y = y.keras.ohc,
shuffle = T,
epochs = 100
)
y <- pd.test.Y
levels(y) = 0:1
y.keras.test.ohc = to_categorical(y , num_classes = 2)
y <- as.factor(pd.test.Y)
levels(y) = 0:1
y.keras.test.ohc = to_categorical(y , num_classes = 2)
evaluate(model, ffnn.test.X.scaled, y.keras.test.ohc, batch_size =1)
y <- as.factor(pd.test.Y)
levels(y) = 0:1
y.keras.test.ohc = to_categorical(y , num_classes = 2)
evaluate(loan.ffnn.keras, ffnn.test.X.scaled, y.keras.test.ohc, batch_size =1)
y <- as.factor(pd.test.Y)
levels(y) = 0:1
y.keras.test.ohc = to_categorical(y , num_classes = 2)
evaluate(ffnn.keras.model, ffnn.test.X.scaled, y.keras.test.ohc, batch_size =1)
y.keras <- as.factor(pd.test.Y)
levels(y.keras) = 0:1
y.keras.test.ohc = to_categorical(y , num_classes = 2)
evaluate(ffnn.keras.model, ffnn.test.X.scaled, y.keras.test.ohc, batch_size =1)
loan.keras.pred.prob<-predict(ffnn.keras.model, ffnn.test.X.scaled, y.keras.test.ohc, batch_size =1)
loan.keras.pred<-as.factor(max.col(loan.keras.pred.prob))
levels(loan.keras.pred)=y.keras.levelnames
loan.keras.pred.prob<-predict(ffnn.keras.model, ffnn.test.X.scaled, y.keras.test.ohc, batch_size =1)
loan.keras.pred<-as.factor(max.col(loan.keras.pred.prob))
levels(loan.keras.pred) <- levels(pd.test.Y)
loan.keras.pred.prob<-predict(ffnn.keras.model, ffnn.test.X.scaled, y.keras.test.ohc, batch_size =1)
loan.keras.pred<-as.factor(max.col(loan.keras.pred.prob))
levels(loan.keras.pred) <- levels(as.factor(pd.test.Y))
table(loan.keras.pred, pd.test.Y)
loan.keras.pred.prob<-predict(ffnn.keras.model, ffnn.test.X.scaled, y.keras.test.ohc, batch_size =1)
loan.keras.pred<-as.factor(max.col(loan.keras.pred.prob))
levels(loan.keras.pred) <- levels(as.factor(pd.test.Y))
keras.pred.table <- table(loan.keras.pred, pd.test.Y)
confusionMatrix(keras.pred.table)
